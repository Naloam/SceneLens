/**
 * UnifiedSceneAnalyzer - ç»Ÿä¸€åœºæ™¯åˆ†æå™¨
 *
 * æ•´åˆé™é»˜ä¸Šä¸‹æ–‡æ£€æµ‹å’Œç”¨æˆ·è§¦å‘æ£€æµ‹ï¼Œå°† ML æ¨¡å‹é¢„æµ‹ç»“æœ
 * æ˜ å°„åˆ°ç»Ÿä¸€çš„ SceneTypeï¼Œå¹¶ç»“åˆåŠ¨æ€å»ºè®®æœåŠ¡ç”Ÿæˆæ™ºèƒ½å»ºè®®
 */

import type {
  SceneType,
  SilentContext,
  ContextSignal,
  TriggeredContext,
  Prediction,
} from '../types';
import { silentContextEngine } from '../sensors';
import { dynamicSuggestionService, TimeOfDay } from '../services/DynamicSuggestionService';
import { feedbackLogger } from '../reflection/FeedbackLogger';
import { weightAdjuster } from '../reflection/WeightAdjuster';

/**
 * ML é¢„æµ‹æ ‡ç­¾åˆ° SceneType çš„æ˜ å°„é…ç½®
 */
const IMAGE_LABEL_TO_SCENE: Record<string, SceneType[]> = {
  // å›¾åƒåˆ†ç±»æ ‡ç­¾
  'indoor_office': ['OFFICE'],
  'indoor_home': ['HOME', 'SLEEP'],
  'outdoor_street': ['COMMUTE', 'TRAVEL'],
  'outdoor_park': ['HOME', 'STUDY'], // å…¬å›­å¯èƒ½æ˜¯ä¼‘é—²æˆ–æˆ·å¤–å­¦ä¹ 
  'transport_subway': ['COMMUTE'],
  'transport_bus': ['COMMUTE'],
  'transport_car': ['COMMUTE', 'TRAVEL'],
  'restaurant': ['HOME'], // é¤å…é€šå¸¸å¯¹åº”ä¼‘é—²æ—¶é—´
  'gym': ['STUDY'], // å¥èº«æˆ¿å¯¹åº”ä¸“æ³¨çŠ¶æ€
  'library': ['STUDY'],
};

const AUDIO_LABEL_TO_SCENE: Record<string, SceneType[]> = {
  // éŸ³é¢‘åˆ†ç±»æ ‡ç­¾
  'silence': ['SLEEP', 'STUDY', 'HOME'],
  'speech': ['OFFICE', 'HOME'],
  'music': ['COMMUTE', 'HOME', 'STUDY'],
  'traffic': ['COMMUTE', 'TRAVEL'],
  'nature': ['HOME', 'TRAVEL'],
  'machinery': ['OFFICE', 'COMMUTE'],
  'crowd': ['COMMUTE', 'TRAVEL'],
  'indoor_quiet': ['HOME', 'STUDY', 'OFFICE'],
  'outdoor_busy': ['COMMUTE', 'TRAVEL'],
};

/**
 * åœºæ™¯åŒ¹é…ç»“æœ
 */
interface SceneMatchResult {
  sceneType: SceneType;
  confidence: number;
  sources: Array<{
    type: 'silent' | 'image' | 'audio' | 'time' | 'location';
    label: string;
    score: number;
  }>;
}

/**
 * ç»Ÿä¸€åˆ†æç»“æœ
 */
export interface UnifiedAnalysisResult {
  /** æœ€ç»ˆç¡®å®šçš„åœºæ™¯ç±»å‹ */
  sceneType: SceneType;
  /** ç»¼åˆç½®ä¿¡åº¦ (0-1) */
  confidence: number;
  /** é™é»˜ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰ */
  silentContext: SilentContext | null;
  /** ML é¢„æµ‹ç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰ */
  mlPredictions: Prediction[] | null;
  /** èåˆåçš„åœºæ™¯åŒ¹é…è¯¦æƒ… */
  matchDetails: SceneMatchResult[];
  /** æ—¶é—´ä¸Šä¸‹æ–‡ */
  timeContext: {
    timeOfDay: TimeOfDay;
    hour: number;
    isWeekend: boolean;
  };
  /** ä¸ªæ€§åŒ–å»ºè®®æ–‡æœ¬ */
  personalizedNotes: string[];
  /** åˆ†ææ—¶é—´æˆ³ */
  timestamp: number;
}

/**
 * ç»Ÿä¸€åœºæ™¯åˆ†æå™¨ç±»
 */
class UnifiedSceneAnalyzerClass {
  private initialized = false;

  /**
   * åˆå§‹åŒ–
   */
  async initialize(): Promise<void> {
    if (this.initialized) return;

    await dynamicSuggestionService.initialize();
    await feedbackLogger.initialize();
    await weightAdjuster.initialize();

    this.initialized = true;
    console.log('[UnifiedSceneAnalyzer] åˆå§‹åŒ–å®Œæˆ');
  }

  /**
   * æ‰§è¡Œç»Ÿä¸€åœºæ™¯åˆ†æ
   * 
   * @param triggeredPredictions ç”¨æˆ·è§¦å‘åˆ†æçš„ ML é¢„æµ‹ç»“æœï¼ˆå¯é€‰ï¼‰
   * @returns ç»Ÿä¸€åˆ†æç»“æœ
   */
  async analyze(triggeredPredictions?: Prediction[]): Promise<UnifiedAnalysisResult> {
    await this.initialize();

    const timestamp = Date.now();
    const matchDetails: SceneMatchResult[] = [];

    // 1. è·å–é™é»˜ä¸Šä¸‹æ–‡ï¼ˆå§‹ç»ˆè·å–ï¼Œä½œä¸ºåŸºç¡€ï¼‰
    let silentContext: SilentContext | null = null;
    try {
      silentContext = await silentContextEngine.getContext();
      console.log('[UnifiedSceneAnalyzer] é™é»˜ä¸Šä¸‹æ–‡:', silentContext.context, 'ç½®ä¿¡åº¦:', silentContext.confidence);
    } catch (error) {
      console.warn('[UnifiedSceneAnalyzer] è·å–é™é»˜ä¸Šä¸‹æ–‡å¤±è´¥:', error);
    }

    // 2. å¤„ç† ML é¢„æµ‹ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    let mlSceneScores: Map<SceneType, number> = new Map();
    if (triggeredPredictions && triggeredPredictions.length > 0) {
      mlSceneScores = this.mapPredictionsToScenes(triggeredPredictions);
      console.log('[UnifiedSceneAnalyzer] ML é¢„æµ‹æ˜ å°„ç»“æœ:', Object.fromEntries(mlSceneScores));
    }

    // 3. è·å–æ—¶é—´ä¸Šä¸‹æ–‡
    const timeContext = this.getTimeContext();

    // 4. èåˆå¤šæºä¿¡å·
    const fusedScores = this.fuseSignals(silentContext, mlSceneScores, timeContext);

    // 5. ç¡®å®šæœ€ç»ˆåœºæ™¯
    let finalScene: SceneType = 'UNKNOWN';
    let finalConfidence = 0;

    for (const [scene, score] of fusedScores.entries()) {
      // åº”ç”¨ç”¨æˆ·åé¦ˆæƒé‡
      const weight = weightAdjuster.getWeight(scene);
      const adjustedScore = score * weight;

      matchDetails.push({
        sceneType: scene,
        confidence: adjustedScore,
        sources: this.getSourcesForScene(scene, silentContext, triggeredPredictions),
      });

      if (adjustedScore > finalConfidence) {
        finalConfidence = adjustedScore;
        finalScene = scene;
      }
    }

    // æŒ‰ç½®ä¿¡åº¦æ’åº
    matchDetails.sort((a, b) => b.confidence - a.confidence);

    // 6. ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
    const personalizedNotes = this.generatePersonalizedNotes(finalScene, timeContext, finalConfidence);

    console.log('[UnifiedSceneAnalyzer] æœ€ç»ˆåœºæ™¯:', finalScene, 'ç½®ä¿¡åº¦:', finalConfidence.toFixed(2));

    return {
      sceneType: finalScene,
      confidence: finalConfidence,
      silentContext,
      mlPredictions: triggeredPredictions || null,
      matchDetails,
      timeContext,
      personalizedNotes,
      timestamp,
    };
  }

  /**
   * å°† ML é¢„æµ‹ç»“æœæ˜ å°„åˆ°åœºæ™¯ç±»å‹
   */
  private mapPredictionsToScenes(predictions: Prediction[]): Map<SceneType, number> {
    const sceneScores: Map<SceneType, number> = new Map();

    for (const pred of predictions) {
      // ç§»é™¤ "image:" æˆ– "audio:" å‰ç¼€
      const [sourceType, rawLabel] = pred.label.includes(':') 
        ? pred.label.split(':') 
        : ['unknown', pred.label];

      const labelMap = sourceType === 'image' ? IMAGE_LABEL_TO_SCENE : AUDIO_LABEL_TO_SCENE;
      const mappedScenes = labelMap[rawLabel] || [];

      for (const scene of mappedScenes) {
        const currentScore = sceneScores.get(scene) || 0;
        // ä½¿ç”¨åŠ æƒç´¯åŠ ï¼Œå¤šä¸ªæ¥æºæŒ‡å‘åŒä¸€åœºæ™¯ä¼šå¢åŠ ç½®ä¿¡åº¦
        sceneScores.set(scene, currentScore + pred.score * 0.5);
      }
    }

    return sceneScores;
  }

  /**
   * èåˆå¤šæºä¿¡å·
   */
  private fuseSignals(
    silentContext: SilentContext | null,
    mlSceneScores: Map<SceneType, number>,
    timeContext: { timeOfDay: TimeOfDay; hour: number; isWeekend: boolean }
  ): Map<SceneType, number> {
    const fusedScores: Map<SceneType, number> = new Map();

    // æƒé‡é…ç½®
    const SILENT_WEIGHT = 0.5;  // é™é»˜ä¸Šä¸‹æ–‡æƒé‡
    const ML_WEIGHT = 0.35;     // ML é¢„æµ‹æƒé‡
    const TIME_WEIGHT = 0.15;   // æ—¶é—´ä¸Šä¸‹æ–‡æƒé‡

    // 1. é™é»˜ä¸Šä¸‹æ–‡è´¡çŒ®
    if (silentContext) {
      const currentScore = fusedScores.get(silentContext.context) || 0;
      fusedScores.set(silentContext.context, currentScore + silentContext.confidence * SILENT_WEIGHT);
    }

    // 2. ML é¢„æµ‹è´¡çŒ®
    for (const [scene, score] of mlSceneScores.entries()) {
      const currentScore = fusedScores.get(scene) || 0;
      fusedScores.set(scene, currentScore + score * ML_WEIGHT);
    }

    // 3. æ—¶é—´ä¸Šä¸‹æ–‡è´¡çŒ®
    const timeBasedScenes = this.getTimeBasedSceneBoosts(timeContext);
    for (const [scene, boost] of timeBasedScenes.entries()) {
      const currentScore = fusedScores.get(scene) || 0;
      fusedScores.set(scene, currentScore + boost * TIME_WEIGHT);
    }

    // å½’ä¸€åŒ–
    const maxScore = Math.max(...fusedScores.values(), 0.01);
    for (const [scene, score] of fusedScores.entries()) {
      fusedScores.set(scene, Math.min(score / maxScore, 1));
    }

    return fusedScores;
  }

  /**
   * æ ¹æ®æ—¶é—´è·å–åœºæ™¯åŠ æƒ
   */
  private getTimeBasedSceneBoosts(
    timeContext: { timeOfDay: TimeOfDay; hour: number; isWeekend: boolean }
  ): Map<SceneType, number> {
    const boosts: Map<SceneType, number> = new Map();
    const { timeOfDay, isWeekend } = timeContext;

    // å·¥ä½œæ—¥é€šå‹¤æ—¶é—´
    if (!isWeekend && (timeOfDay === 'morning')) {
      // æ—©ä¸Š 7-9 ç‚¹
      if (timeContext.hour >= 7 && timeContext.hour < 9) {
        boosts.set('COMMUTE', 0.9);
      }
    }

    // æ™šé«˜å³°
    if (!isWeekend && timeOfDay === 'afternoon') {
      if (timeContext.hour >= 17 && timeContext.hour < 19) {
        boosts.set('COMMUTE', 0.8);
      }
    }

    // å·¥ä½œæ—¶é—´
    if (!isWeekend && (timeOfDay === 'morning' || timeOfDay === 'afternoon')) {
      if (timeContext.hour >= 9 && timeContext.hour < 18) {
        boosts.set('OFFICE', 0.7);
      }
    }

    // æ™šä¸Šå­¦ä¹ æ—¶é—´
    if (timeOfDay === 'evening') {
      boosts.set('STUDY', 0.6);
      boosts.set('HOME', 0.5);
    }

    // æ·±å¤œç¡çœ æ—¶é—´
    if (timeOfDay === 'night') {
      boosts.set('SLEEP', 0.9);
      boosts.set('HOME', 0.4);
    }

    // å‘¨æœ«åœ¨å®¶
    if (isWeekend) {
      boosts.set('HOME', (boosts.get('HOME') || 0) + 0.3);
    }

    return boosts;
  }

  /**
   * è·å–åœºæ™¯çš„ä¿¡å·æ¥æº
   */
  private getSourcesForScene(
    scene: SceneType,
    silentContext: SilentContext | null,
    mlPredictions?: Prediction[]
  ): SceneMatchResult['sources'] {
    const sources: SceneMatchResult['sources'] = [];

    // é™é»˜ä¸Šä¸‹æ–‡æ¥æº
    if (silentContext && silentContext.context === scene) {
      sources.push({
        type: 'silent',
        label: `é™é»˜æ£€æµ‹: ${scene}`,
        score: silentContext.confidence,
      });

      // æ·»åŠ å…·ä½“ä¿¡å·
      for (const signal of silentContext.signals) {
        sources.push({
          type: signal.type === 'TIME' ? 'time' : 
                signal.type === 'LOCATION' ? 'location' : 'silent',
          label: `${signal.type}: ${signal.value}`,
          score: signal.weight,
        });
      }
    }

    // ML é¢„æµ‹æ¥æº
    if (mlPredictions) {
      for (const pred of mlPredictions) {
        const [sourceType, rawLabel] = pred.label.includes(':') 
          ? pred.label.split(':') 
          : ['unknown', pred.label];

        const labelMap = sourceType === 'image' ? IMAGE_LABEL_TO_SCENE : AUDIO_LABEL_TO_SCENE;
        const mappedScenes = labelMap[rawLabel] || [];

        if (mappedScenes.includes(scene)) {
          sources.push({
            type: sourceType === 'image' ? 'image' : 'audio',
            label: `${sourceType}: ${rawLabel}`,
            score: pred.score,
          });
        }
      }
    }

    return sources;
  }

  /**
   * è·å–æ—¶é—´ä¸Šä¸‹æ–‡
   */
  private getTimeContext(): { timeOfDay: TimeOfDay; hour: number; isWeekend: boolean } {
    const now = new Date();
    const hour = now.getHours();
    const dayOfWeek = now.getDay();

    return {
      timeOfDay: dynamicSuggestionService.getTimeOfDay(now),
      hour,
      isWeekend: dayOfWeek === 0 || dayOfWeek === 6,
    };
  }

  /**
   * ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®æ–‡æœ¬
   */
  private generatePersonalizedNotes(
    scene: SceneType,
    timeContext: { timeOfDay: TimeOfDay; hour: number; isWeekend: boolean },
    confidence: number
  ): string[] {
    const notes: string[] = [];

    // æ·»åŠ é—®å€™è¯­
    notes.push(dynamicSuggestionService.getGreeting(scene));

    // æ·»åŠ åœºæ™¯è¯´æ˜
    const sceneName = this.getSceneDisplayName(scene);
    if (confidence > 0.7) {
      notes.push(`âœ¨ æ£€æµ‹åˆ°æ‚¨å¤„äº${sceneName}çŠ¶æ€`);
    } else if (confidence > 0.4) {
      notes.push(`ğŸ“ å¯èƒ½å¤„äº${sceneName}çŠ¶æ€`);
    } else {
      notes.push(`ğŸ’¡ æ­£åœ¨å°è¯•è¯†åˆ«æ‚¨çš„åœºæ™¯...`);
    }

    // æ·»åŠ æ—¶é—´ç›¸å…³æç¤º
    notes.push(dynamicSuggestionService.getTip(scene));

    return notes;
  }

  /**
   * è·å–åœºæ™¯æ˜¾ç¤ºåç§°
   */
  private getSceneDisplayName(scene: SceneType): string {
    const names: Record<SceneType, string> = {
      COMMUTE: 'é€šå‹¤',
      OFFICE: 'åŠå…¬',
      HOME: 'å±…å®¶',
      STUDY: 'å­¦ä¹ ',
      SLEEP: 'ä¼‘æ¯',
      TRAVEL: 'å‡ºè¡Œ',
      UNKNOWN: 'æœªçŸ¥',
    };
    return names[scene] || 'æœªçŸ¥';
  }

  /**
   * å°†è§¦å‘åˆ†æç»“æœè½¬æ¢ä¸º SilentContext æ ¼å¼ï¼ˆå…¼å®¹ç°æœ‰ä»£ç ï¼‰
   */
  convertToSilentContext(result: UnifiedAnalysisResult): SilentContext {
    const signals: ContextSignal[] = [];

    // ä» matchDetails æå–ä¿¡å·
    if (result.matchDetails.length > 0) {
      for (const source of result.matchDetails[0].sources) {
        signals.push({
          type: source.type === 'time' ? 'TIME' : 
                source.type === 'location' ? 'LOCATION' : 
                source.type === 'image' ? 'FOREGROUND_APP' : 'MOTION',
          value: source.label,
          weight: source.score,
          timestamp: result.timestamp,
        });
      }
    }

    return {
      timestamp: result.timestamp,
      context: result.sceneType,
      confidence: result.confidence,
      signals,
    };
  }

  /**
   * è®°å½•ç”¨æˆ·åé¦ˆ
   */
  async recordFeedback(
    result: UnifiedAnalysisResult,
    action: 'accept' | 'ignore' | 'cancel'
  ): Promise<void> {
    // ç›´æ¥ä½¿ç”¨ actionï¼Œå› ä¸º UserFeedback ç±»å‹å°±æ˜¯ 'accept' | 'ignore' | 'cancel'
    await feedbackLogger.logFeedback(
      result.sceneType,
      action,
      result.confidence,
      result.matchDetails[0]?.sources.map(s => s.label) || [],
      action === 'accept' ? ['scene_executed'] : undefined
    );

    // è§¦å‘æƒé‡è°ƒæ•´æ£€æŸ¥
    const recommendations = weightAdjuster.getAdjustmentRecommendations();
    for (const rec of recommendations) {
      if (rec.autoApply) {
        await weightAdjuster.applyRecommendation(rec);
        console.log(`[UnifiedSceneAnalyzer] è‡ªåŠ¨åº”ç”¨æƒé‡è°ƒæ•´: ${rec.sceneType} -> ${rec.suggestedWeight.toFixed(2)}`);
      }
    }
  }
}

export const unifiedSceneAnalyzer = new UnifiedSceneAnalyzerClass();
export default unifiedSceneAnalyzer;
